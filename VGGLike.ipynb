{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.applications import VGG16\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard, ReduceLROnPlateau\n",
    "from keras.layers import Dense, Dropout, Conv2D, MaxPooling2D, Flatten, BatchNormalization, Lambda\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Model, Sequential\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Use ImageDataGenerator for data augmentation and resizing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_dir = 'data/faces/train'\n",
    "val_dir = 'data/faces/val'\n",
    "test_dir = 'data/test'\n",
    "batch_size = 32\n",
    "\n",
    "def generate(generator, directory, classes, batch_size):\n",
    "    return generator.flow_from_directory(directory,\n",
    "                                         target_size=(112,112),\n",
    "                                         classes=classes,\n",
    "                                         class_mode='categorical',\n",
    "                                         batch_size=batch_size,\n",
    "                                         shuffle=True,\n",
    "                                         color_mode='grayscale')\n",
    "\n",
    "def generate_augmented_batches(directory, batch_size=32, classes=None):\n",
    "    gen = ImageDataGenerator(rotation_range=15,\n",
    "                             width_shift_range=0.07,\n",
    "                             height_shift_range=0.07,\n",
    "                             shear_range=0.03,\n",
    "                             horizontal_flip=True,)\n",
    "    return generate(gen, directory, classes, batch_size)\n",
    "\n",
    "def generate_batches(directory, batch_size=32, classes=None):\n",
    "    gen = ImageDataGenerator()\n",
    "    return generate(gen, directory, classes, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 14961 images belonging to 3 classes.\n",
      "Found 1214 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "train_batches = generate_augmented_batches(train_dir, batch_size)\n",
    "val_batches = generate_batches(val_dir, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mean_pixel_value = 126.945034642"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def zero_center_fn(x):\n",
    "    return x - mean_pixel_value\n",
    "\n",
    "def add_conv_block(model, layers, filters):\n",
    "    for _ in range(layers):\n",
    "        model.add(Conv2D(filters, 3, padding='same', activation='relu'))\n",
    "        model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D())\n",
    "    \n",
    "def add_dense_block(model, layers, nodes, dropout):\n",
    "    for _ in range(layers):\n",
    "        model.add(Dense(nodes))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(dropout))\n",
    "    \n",
    "def vgg_like(dropout=0.5, zero_center=False):\n",
    "    model = Sequential()\n",
    "    \n",
    "    if(zero_center):\n",
    "        model.add(Lambda(zero_center_fn, input_shape=(112,112,1)))\n",
    "        add_conv_block(model, 2, 32)\n",
    "    else:\n",
    "        model.add(Conv2D(32, 3, padding='same', activation='relu', input_shape=(112,112,1)))\n",
    "        model.add(BatchNormalization())\n",
    "        add_conv_block(model, 1, 32)\n",
    "        \n",
    "    add_conv_block(model, 1, 64)\n",
    "    add_conv_block(model, 2, 128)\n",
    "    add_conv_block(model, 2, 256)\n",
    "    model.add(Flatten())\n",
    "    add_dense_block(model, 2, 4096, dropout)\n",
    "    model.add(Dense(3, activation='softmax'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(model,\n",
    "          training_batches,\n",
    "          validation_batches,\n",
    "          model_filename,\n",
    "          batch_size=64,\n",
    "          epochs=100,\n",
    "          lr=5e-4,\n",
    "          patience=10,\n",
    "          min_lr=1e-7,\n",
    "          reduce_factor=0.5,\n",
    "          log_dir='/home/ubuntu/nbs/tensorboard_logs',\n",
    "          initial_epoch=0):\n",
    "    model.compile(optimizer=Adam(lr=lr), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    # Add various callbacks: checkpointing on best validation loss, tensorboard for viewing loss function\n",
    "    # and learning rate decay for dropping learning rate when learning has hit a plateau.\n",
    "    checkpoint = ModelCheckpoint(model_filename, save_best_only=True, monitor='val_loss')\n",
    "    tensorboard = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "    lrdecay = ReduceLROnPlateau(monitor='val_loss', factor=reduce_factor, patience=patience, min_lr=min_lr)\n",
    "    \n",
    "    history2 = model.fit_generator(training_batches,\n",
    "                                  steps_per_epoch=(14961 // batch_size),\n",
    "                                  validation_data=validation_batches,\n",
    "                                  validation_steps=(1214 // batch_size),\n",
    "                                  callbacks=[checkpoint, tensorboard, lrdecay],\n",
    "                                  epochs=epochs,\n",
    "                                  initial_epoch=initial_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = vgg_like(dropout=0.875, zero_center=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name conv2d_8/kernel:0 is illegal; using conv2d_8/kernel_0 instead.\n",
      "INFO:tensorflow:Summary name conv2d_8/bias:0 is illegal; using conv2d_8/bias_0 instead.\n",
      "INFO:tensorflow:Summary name batch_normalization_10/gamma:0 is illegal; using batch_normalization_10/gamma_0 instead.\n",
      "INFO:tensorflow:Summary name batch_normalization_10/beta:0 is illegal; using batch_normalization_10/beta_0 instead.\n",
      "INFO:tensorflow:Summary name batch_normalization_10/moving_mean:0 is illegal; using batch_normalization_10/moving_mean_0 instead.\n",
      "INFO:tensorflow:Summary name batch_normalization_10/moving_variance:0 is illegal; using batch_normalization_10/moving_variance_0 instead.\n",
      "INFO:tensorflow:Summary name conv2d_9/kernel:0 is illegal; using conv2d_9/kernel_0 instead.\n",
      "INFO:tensorflow:Summary name conv2d_9/bias:0 is illegal; using conv2d_9/bias_0 instead.\n",
      "INFO:tensorflow:Summary name batch_normalization_11/gamma:0 is illegal; using batch_normalization_11/gamma_0 instead.\n",
      "INFO:tensorflow:Summary name batch_normalization_11/beta:0 is illegal; using batch_normalization_11/beta_0 instead.\n",
      "INFO:tensorflow:Summary name batch_normalization_11/moving_mean:0 is illegal; using batch_normalization_11/moving_mean_0 instead.\n",
      "INFO:tensorflow:Summary name batch_normalization_11/moving_variance:0 is illegal; using batch_normalization_11/moving_variance_0 instead.\n",
      "INFO:tensorflow:Summary name conv2d_10/kernel:0 is illegal; using conv2d_10/kernel_0 instead.\n",
      "INFO:tensorflow:Summary name conv2d_10/bias:0 is illegal; using conv2d_10/bias_0 instead.\n",
      "INFO:tensorflow:Summary name batch_normalization_12/gamma:0 is illegal; using batch_normalization_12/gamma_0 instead.\n",
      "INFO:tensorflow:Summary name batch_normalization_12/beta:0 is illegal; using batch_normalization_12/beta_0 instead.\n",
      "INFO:tensorflow:Summary name batch_normalization_12/moving_mean:0 is illegal; using batch_normalization_12/moving_mean_0 instead.\n",
      "INFO:tensorflow:Summary name batch_normalization_12/moving_variance:0 is illegal; using batch_normalization_12/moving_variance_0 instead.\n",
      "INFO:tensorflow:Summary name conv2d_11/kernel:0 is illegal; using conv2d_11/kernel_0 instead.\n",
      "INFO:tensorflow:Summary name conv2d_11/bias:0 is illegal; using conv2d_11/bias_0 instead.\n",
      "INFO:tensorflow:Summary name batch_normalization_13/gamma:0 is illegal; using batch_normalization_13/gamma_0 instead.\n",
      "INFO:tensorflow:Summary name batch_normalization_13/beta:0 is illegal; using batch_normalization_13/beta_0 instead.\n",
      "INFO:tensorflow:Summary name batch_normalization_13/moving_mean:0 is illegal; using batch_normalization_13/moving_mean_0 instead.\n",
      "INFO:tensorflow:Summary name batch_normalization_13/moving_variance:0 is illegal; using batch_normalization_13/moving_variance_0 instead.\n",
      "INFO:tensorflow:Summary name conv2d_12/kernel:0 is illegal; using conv2d_12/kernel_0 instead.\n",
      "INFO:tensorflow:Summary name conv2d_12/bias:0 is illegal; using conv2d_12/bias_0 instead.\n",
      "INFO:tensorflow:Summary name batch_normalization_14/gamma:0 is illegal; using batch_normalization_14/gamma_0 instead.\n",
      "INFO:tensorflow:Summary name batch_normalization_14/beta:0 is illegal; using batch_normalization_14/beta_0 instead.\n",
      "INFO:tensorflow:Summary name batch_normalization_14/moving_mean:0 is illegal; using batch_normalization_14/moving_mean_0 instead.\n",
      "INFO:tensorflow:Summary name batch_normalization_14/moving_variance:0 is illegal; using batch_normalization_14/moving_variance_0 instead.\n",
      "INFO:tensorflow:Summary name conv2d_13/kernel:0 is illegal; using conv2d_13/kernel_0 instead.\n",
      "INFO:tensorflow:Summary name conv2d_13/bias:0 is illegal; using conv2d_13/bias_0 instead.\n",
      "INFO:tensorflow:Summary name batch_normalization_15/gamma:0 is illegal; using batch_normalization_15/gamma_0 instead.\n",
      "INFO:tensorflow:Summary name batch_normalization_15/beta:0 is illegal; using batch_normalization_15/beta_0 instead.\n",
      "INFO:tensorflow:Summary name batch_normalization_15/moving_mean:0 is illegal; using batch_normalization_15/moving_mean_0 instead.\n",
      "INFO:tensorflow:Summary name batch_normalization_15/moving_variance:0 is illegal; using batch_normalization_15/moving_variance_0 instead.\n",
      "INFO:tensorflow:Summary name conv2d_14/kernel:0 is illegal; using conv2d_14/kernel_0 instead.\n",
      "INFO:tensorflow:Summary name conv2d_14/bias:0 is illegal; using conv2d_14/bias_0 instead.\n",
      "INFO:tensorflow:Summary name batch_normalization_16/gamma:0 is illegal; using batch_normalization_16/gamma_0 instead.\n",
      "INFO:tensorflow:Summary name batch_normalization_16/beta:0 is illegal; using batch_normalization_16/beta_0 instead.\n",
      "INFO:tensorflow:Summary name batch_normalization_16/moving_mean:0 is illegal; using batch_normalization_16/moving_mean_0 instead.\n",
      "INFO:tensorflow:Summary name batch_normalization_16/moving_variance:0 is illegal; using batch_normalization_16/moving_variance_0 instead.\n",
      "INFO:tensorflow:Summary name dense_4/kernel:0 is illegal; using dense_4/kernel_0 instead.\n",
      "INFO:tensorflow:Summary name dense_4/bias:0 is illegal; using dense_4/bias_0 instead.\n",
      "INFO:tensorflow:Summary name batch_normalization_17/gamma:0 is illegal; using batch_normalization_17/gamma_0 instead.\n",
      "INFO:tensorflow:Summary name batch_normalization_17/beta:0 is illegal; using batch_normalization_17/beta_0 instead.\n",
      "INFO:tensorflow:Summary name batch_normalization_17/moving_mean:0 is illegal; using batch_normalization_17/moving_mean_0 instead.\n",
      "INFO:tensorflow:Summary name batch_normalization_17/moving_variance:0 is illegal; using batch_normalization_17/moving_variance_0 instead.\n",
      "INFO:tensorflow:Summary name dense_5/kernel:0 is illegal; using dense_5/kernel_0 instead.\n",
      "INFO:tensorflow:Summary name dense_5/bias:0 is illegal; using dense_5/bias_0 instead.\n",
      "INFO:tensorflow:Summary name batch_normalization_18/gamma:0 is illegal; using batch_normalization_18/gamma_0 instead.\n",
      "INFO:tensorflow:Summary name batch_normalization_18/beta:0 is illegal; using batch_normalization_18/beta_0 instead.\n",
      "INFO:tensorflow:Summary name batch_normalization_18/moving_mean:0 is illegal; using batch_normalization_18/moving_mean_0 instead.\n",
      "INFO:tensorflow:Summary name batch_normalization_18/moving_variance:0 is illegal; using batch_normalization_18/moving_variance_0 instead.\n",
      "INFO:tensorflow:Summary name dense_6/kernel:0 is illegal; using dense_6/kernel_0 instead.\n",
      "INFO:tensorflow:Summary name dense_6/bias:0 is illegal; using dense_6/bias_0 instead.\n",
      "Epoch 1/120\n",
      "467/467 [==============================] - 125s - loss: 2.6119 - acc: 0.4419 - val_loss: 0.9142 - val_acc: 0.5870\n",
      "Epoch 2/120\n",
      "467/467 [==============================] - 122s - loss: 1.6268 - acc: 0.5313 - val_loss: 1.0217 - val_acc: 0.6117\n",
      "Epoch 3/120\n",
      "467/467 [==============================] - 123s - loss: 1.5506 - acc: 0.5451 - val_loss: 0.7568 - val_acc: 0.6785\n",
      "Epoch 4/120\n",
      "467/467 [==============================] - 121s - loss: 1.3208 - acc: 0.5993 - val_loss: 0.8376 - val_acc: 0.6269\n",
      "Epoch 5/120\n",
      "467/467 [==============================] - 121s - loss: 1.3541 - acc: 0.5848 - val_loss: 0.8399 - val_acc: 0.6591\n",
      "Epoch 6/120\n",
      "467/467 [==============================] - 123s - loss: 1.2425 - acc: 0.6161 - val_loss: 0.7555 - val_acc: 0.6836\n",
      "Epoch 7/120\n",
      "467/467 [==============================] - 121s - loss: 1.2018 - acc: 0.6293 - val_loss: 0.9151 - val_acc: 0.6066\n",
      "Epoch 8/120\n",
      "467/467 [==============================] - 121s - loss: 1.1771 - acc: 0.6385 - val_loss: 1.1553 - val_acc: 0.6734\n",
      "Epoch 9/120\n",
      "467/467 [==============================] - 121s - loss: 1.0829 - acc: 0.6370 - val_loss: 0.8288 - val_acc: 0.7318\n",
      "Epoch 10/120\n",
      "467/467 [==============================] - 123s - loss: 0.8885 - acc: 0.6576 - val_loss: 0.6208 - val_acc: 0.7521\n",
      "Epoch 11/120\n",
      "467/467 [==============================] - 121s - loss: 0.7585 - acc: 0.6954 - val_loss: 0.6723 - val_acc: 0.7640\n",
      "Epoch 12/120\n",
      "467/467 [==============================] - 121s - loss: 0.7550 - acc: 0.7037 - val_loss: 0.6898 - val_acc: 0.7657\n",
      "Epoch 13/120\n",
      "467/467 [==============================] - 121s - loss: 0.7338 - acc: 0.7089 - val_loss: 0.6221 - val_acc: 0.7640\n",
      "Epoch 14/120\n",
      "467/467 [==============================] - 123s - loss: 0.7363 - acc: 0.7121 - val_loss: 0.5808 - val_acc: 0.7707\n",
      "Epoch 15/120\n",
      "467/467 [==============================] - 122s - loss: 0.7258 - acc: 0.7163 - val_loss: 0.6196 - val_acc: 0.7572\n",
      "Epoch 16/120\n",
      "467/467 [==============================] - 122s - loss: 0.7138 - acc: 0.7243 - val_loss: 0.8297 - val_acc: 0.7208\n",
      "Epoch 17/120\n",
      "467/467 [==============================] - 122s - loss: 0.6997 - acc: 0.7346 - val_loss: 0.6172 - val_acc: 0.7699\n",
      "Epoch 18/120\n",
      "467/467 [==============================] - 123s - loss: 0.6878 - acc: 0.7365 - val_loss: 0.5519 - val_acc: 0.7775\n",
      "Epoch 19/120\n",
      "467/467 [==============================] - 122s - loss: 0.6577 - acc: 0.7424 - val_loss: 0.5793 - val_acc: 0.7750\n",
      "Epoch 20/120\n",
      "467/467 [==============================] - 123s - loss: 0.6824 - acc: 0.7388 - val_loss: 0.4906 - val_acc: 0.8215\n",
      "Epoch 21/120\n",
      "467/467 [==============================] - 122s - loss: 0.6416 - acc: 0.7493 - val_loss: 0.5374 - val_acc: 0.7902\n",
      "Epoch 22/120\n",
      "467/467 [==============================] - 122s - loss: 0.6198 - acc: 0.7557 - val_loss: 0.5342 - val_acc: 0.7885\n",
      "Epoch 23/120\n",
      "467/467 [==============================] - 122s - loss: 0.6065 - acc: 0.7676 - val_loss: 0.5981 - val_acc: 0.7614\n",
      "Epoch 24/120\n",
      "467/467 [==============================] - 122s - loss: 0.6651 - acc: 0.7450 - val_loss: 0.6714 - val_acc: 0.7860\n",
      "Epoch 25/120\n",
      "467/467 [==============================] - 122s - loss: 0.6218 - acc: 0.7599 - val_loss: 0.5864 - val_acc: 0.7631\n",
      "Epoch 26/120\n",
      "467/467 [==============================] - 122s - loss: 0.6480 - acc: 0.7547 - val_loss: 0.6262 - val_acc: 0.7284\n",
      "Epoch 27/120\n",
      "467/467 [==============================] - 122s - loss: 0.6289 - acc: 0.7528 - val_loss: 0.5090 - val_acc: 0.8215\n",
      "Epoch 28/120\n",
      "467/467 [==============================] - 122s - loss: 0.5875 - acc: 0.7725 - val_loss: 0.4979 - val_acc: 0.8181\n",
      "Epoch 29/120\n",
      "467/467 [==============================] - 122s - loss: 0.5572 - acc: 0.7827 - val_loss: 0.5052 - val_acc: 0.7995\n",
      "Epoch 30/120\n",
      "467/467 [==============================] - 122s - loss: 0.5873 - acc: 0.7842 - val_loss: 0.5034 - val_acc: 0.7902\n",
      "Epoch 31/120\n",
      "467/467 [==============================] - 122s - loss: 0.5622 - acc: 0.7813 - val_loss: 0.4969 - val_acc: 0.7902\n",
      "Epoch 32/120\n",
      "467/467 [==============================] - 123s - loss: 0.5364 - acc: 0.7965 - val_loss: 0.4618 - val_acc: 0.8359\n",
      "Epoch 33/120\n",
      "467/467 [==============================] - 122s - loss: 0.5022 - acc: 0.8070 - val_loss: 0.4961 - val_acc: 0.8054\n",
      "Epoch 34/120\n",
      "467/467 [==============================] - 123s - loss: 0.4949 - acc: 0.8071 - val_loss: 0.4344 - val_acc: 0.8299\n",
      "Epoch 35/120\n",
      "467/467 [==============================] - 122s - loss: 0.4826 - acc: 0.8179 - val_loss: 0.4401 - val_acc: 0.8460\n",
      "Epoch 36/120\n",
      "467/467 [==============================] - 122s - loss: 0.4785 - acc: 0.8151 - val_loss: 0.4786 - val_acc: 0.8190\n",
      "Epoch 37/120\n",
      "467/467 [==============================] - 122s - loss: 0.4692 - acc: 0.8240 - val_loss: 0.4947 - val_acc: 0.7978\n",
      "Epoch 38/120\n",
      "467/467 [==============================] - 122s - loss: 0.4798 - acc: 0.8187 - val_loss: 0.4870 - val_acc: 0.8198\n",
      "Epoch 39/120\n",
      "467/467 [==============================] - 122s - loss: 0.4552 - acc: 0.8274 - val_loss: 0.4540 - val_acc: 0.8336\n",
      "Epoch 40/120\n",
      "467/467 [==============================] - 122s - loss: 0.4465 - acc: 0.8337 - val_loss: 0.4792 - val_acc: 0.8266\n",
      "Epoch 41/120\n",
      "467/467 [==============================] - 122s - loss: 0.4578 - acc: 0.8276 - val_loss: 0.4639 - val_acc: 0.8350\n",
      "Epoch 42/120\n",
      "467/467 [==============================] - 122s - loss: 0.4492 - acc: 0.8362 - val_loss: 0.4867 - val_acc: 0.8240\n",
      "Epoch 43/120\n",
      "467/467 [==============================] - 122s - loss: 0.4308 - acc: 0.8350 - val_loss: 0.4932 - val_acc: 0.8088\n",
      "Epoch 44/120\n",
      "467/467 [==============================] - 122s - loss: 0.4316 - acc: 0.8346 - val_loss: 0.4768 - val_acc: 0.8266\n",
      "Epoch 45/120\n",
      "467/467 [==============================] - 122s - loss: 0.4143 - acc: 0.8424 - val_loss: 0.4411 - val_acc: 0.8223\n",
      "Epoch 46/120\n",
      "467/467 [==============================] - 122s - loss: 0.4053 - acc: 0.8470 - val_loss: 0.4481 - val_acc: 0.8342\n",
      "Epoch 47/120\n",
      "467/467 [==============================] - 123s - loss: 0.3947 - acc: 0.8554 - val_loss: 0.4330 - val_acc: 0.8393\n",
      "Epoch 48/120\n",
      "467/467 [==============================] - 122s - loss: 0.3768 - acc: 0.8573 - val_loss: 0.4534 - val_acc: 0.8342\n",
      "Epoch 49/120\n",
      "467/467 [==============================] - 122s - loss: 0.3738 - acc: 0.8653 - val_loss: 0.4494 - val_acc: 0.8393\n",
      "Epoch 50/120\n",
      "467/467 [==============================] - 122s - loss: 0.3728 - acc: 0.8591 - val_loss: 0.4527 - val_acc: 0.8308\n",
      "Epoch 51/120\n",
      "467/467 [==============================] - 122s - loss: 0.3603 - acc: 0.8648 - val_loss: 0.4480 - val_acc: 0.8266\n",
      "Epoch 52/120\n",
      "467/467 [==============================] - 122s - loss: 0.3524 - acc: 0.8635 - val_loss: 0.4428 - val_acc: 0.8426\n",
      "Epoch 53/120\n",
      "467/467 [==============================] - 122s - loss: 0.3715 - acc: 0.8643 - val_loss: 0.4813 - val_acc: 0.8190\n",
      "Epoch 54/120\n",
      "467/467 [==============================] - 122s - loss: 0.3667 - acc: 0.8662 - val_loss: 0.4476 - val_acc: 0.8342\n",
      "Epoch 55/120\n",
      "467/467 [==============================] - 122s - loss: 0.3637 - acc: 0.8665 - val_loss: 0.5218 - val_acc: 0.8164\n",
      "Epoch 56/120\n",
      "467/467 [==============================] - 122s - loss: 0.3401 - acc: 0.8773 - val_loss: 0.4564 - val_acc: 0.8359\n",
      "Epoch 57/120\n",
      "467/467 [==============================] - 122s - loss: 0.3401 - acc: 0.8731 - val_loss: 0.4375 - val_acc: 0.8376\n",
      "Epoch 58/120\n",
      "467/467 [==============================] - 122s - loss: 0.3395 - acc: 0.8701 - val_loss: 0.4456 - val_acc: 0.8494\n",
      "Epoch 59/120\n",
      "467/467 [==============================] - 123s - loss: 0.3186 - acc: 0.8822 - val_loss: 0.4157 - val_acc: 0.8536\n",
      "Epoch 60/120\n",
      "467/467 [==============================] - 122s - loss: 0.3263 - acc: 0.8786 - val_loss: 0.4519 - val_acc: 0.8291\n",
      "Epoch 61/120\n",
      "467/467 [==============================] - 122s - loss: 0.3262 - acc: 0.8804 - val_loss: 0.4293 - val_acc: 0.8477\n",
      "Epoch 62/120\n",
      "467/467 [==============================] - 122s - loss: 0.3136 - acc: 0.8832 - val_loss: 0.4590 - val_acc: 0.8283\n",
      "Epoch 63/120\n",
      "467/467 [==============================] - 122s - loss: 0.3107 - acc: 0.8872 - val_loss: 0.4372 - val_acc: 0.8409\n",
      "Epoch 64/120\n",
      "467/467 [==============================] - 122s - loss: 0.2950 - acc: 0.8900 - val_loss: 0.4572 - val_acc: 0.8342\n",
      "Epoch 65/120\n",
      "467/467 [==============================] - 122s - loss: 0.2947 - acc: 0.8903 - val_loss: 0.4412 - val_acc: 0.8418\n",
      "Epoch 66/120\n",
      "467/467 [==============================] - 122s - loss: 0.3101 - acc: 0.8832 - val_loss: 0.4520 - val_acc: 0.8257\n",
      "Epoch 67/120\n",
      "467/467 [==============================] - 122s - loss: 0.2889 - acc: 0.8931 - val_loss: 0.4459 - val_acc: 0.8316\n",
      "Epoch 68/120\n",
      "467/467 [==============================] - 122s - loss: 0.3040 - acc: 0.8893 - val_loss: 0.4971 - val_acc: 0.8215\n",
      "Epoch 69/120\n",
      "467/467 [==============================] - 122s - loss: 0.2976 - acc: 0.8921 - val_loss: 0.4793 - val_acc: 0.8308\n",
      "Epoch 70/120\n",
      "467/467 [==============================] - 122s - loss: 0.3070 - acc: 0.8887 - val_loss: 0.4604 - val_acc: 0.8376\n",
      "Epoch 71/120\n",
      "467/467 [==============================] - 122s - loss: 0.2731 - acc: 0.8981 - val_loss: 0.4746 - val_acc: 0.8257\n",
      "Epoch 72/120\n",
      "467/467 [==============================] - 122s - loss: 0.2774 - acc: 0.8974 - val_loss: 0.4655 - val_acc: 0.8325\n",
      "Epoch 73/120\n",
      "467/467 [==============================] - 122s - loss: 0.2920 - acc: 0.8952 - val_loss: 0.4777 - val_acc: 0.8333\n",
      "Epoch 74/120\n",
      "467/467 [==============================] - 122s - loss: 0.2827 - acc: 0.8970 - val_loss: 0.5040 - val_acc: 0.8215\n",
      "Epoch 75/120\n",
      "467/467 [==============================] - 122s - loss: 0.2775 - acc: 0.8994 - val_loss: 0.4826 - val_acc: 0.8316\n",
      "Epoch 76/120\n",
      "293/467 [=================>............] - ETA: 44s - loss: 0.2805 - acc: 0.8960"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m----------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-aa2471a80c28>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel_file_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'models/vgg_like_dp875/vgg.{epoch:02d}-{val_loss:.4f}.hdf5'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_batches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_batches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_file_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-6-f42abc724bbb>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, training_batches, validation_batches, model_filename, batch_size, epochs, lr, patience, min_lr, reduce_factor, log_dir, initial_epoch)\u001b[0m\n\u001b[1;32m     21\u001b[0m                                   \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensorboard\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlrdecay\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m                                   \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m                                   initial_epoch=initial_epoch)\n\u001b[0m",
      "\u001b[0;32m/home/ubuntu/anaconda2/envs/tf/lib/python3.5/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     87\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 88\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_support_signature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetargspec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/envs/tf/lib/python3.5/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_q_size, workers, pickle_safe, initial_epoch)\u001b[0m\n\u001b[1;32m   1095\u001b[0m                                         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1096\u001b[0m                                         \u001b[0mpickle_safe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpickle_safe\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1097\u001b[0;31m                                         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1098\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1099\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/envs/tf/lib/python3.5/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     87\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 88\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_support_signature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetargspec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/envs/tf/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_q_size, workers, pickle_safe, initial_epoch)\u001b[0m\n\u001b[1;32m   1874\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[1;32m   1875\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1876\u001b[0;31m                                                class_weight=class_weight)\n\u001b[0m\u001b[1;32m   1877\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1878\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/envs/tf/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1618\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/envs/tf/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2071\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2072\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[0;32m-> 2073\u001b[0;31m                               feed_dict=feed_dict)\n\u001b[0m\u001b[1;32m   2074\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2075\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/envs/tf/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    776\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 778\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    779\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/envs/tf/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    980\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 982\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    983\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/envs/tf/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1030\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1032\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1033\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/envs/tf/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1037\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1040\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/envs/tf/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1019\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1020\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_file_path = 'models/vgg_like_dp875/vgg.{epoch:02d}-{val_loss:.4f}.hdf5'\n",
    "train(model, train_batches, val_batches, model_file_path, epochs=120, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load Best Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.load_weights('models/vgg_like_dp875/vgg.58-0.4157.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load Images**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_images = np.genfromtxt('test_data.csv', delimiter=',').reshape((-1,48,48)).astype(np.uint8)\n",
    "nb_images = test_images.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Save images as jpgs so we can exploit ImageDataGenerator for resizing.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "test_dir = 'data/faces/test/'\n",
    "for i in range(nb_images):\n",
    "    img = Image.fromarray(test_images[i])\n",
    "    img.save(test_dir + 'unknown/' + str(i) + '.jpg', 'JPEG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3965 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "test_batches = generate_batches(test_dir, classes=['unknown'], batch_size=5)\n",
    "nb_batches = 3965 / 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = np.argmax(model.predict_generator(test_batches, nb_batches), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Write predictions to csv file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = test_batches.filenames\n",
    "ids = np.array([int(f[8:f.find('.')]) for f in filenames])\n",
    "sorted_idx = np.argsort(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub_file_name = 'vgg_like.csv'\n",
    "submission_matrix = np.stack([ids[sorted_idx], predictions[sorted_idx]], axis=1)\n",
    "np.savetxt(sub_file_name, submission_matrix, delimiter=',', fmt='%d,%d', header='Id,Category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
